# Ivan ğŸ¤–

An intelligent assistant designed to optimize solutions engineering workflows.

<!-- Screenshot: follow-up email draft -->
![Follow-Up Email Draft screenshot](docs/images/UI_screenshot.png)

_Figure: Follow-up email draft generated by Ivan (screenshot)._ 

## Why Ivan?

<table>
<tr>
<td align="center" width="25%">
  <h3>ğŸ”’ Fully Private</h3>
  <p>Runs entirely on your machine or private infrastructure. No data leaves your environment â€” ever.</p>
</td>
<td align="center" width="25%">
  <h3>ğŸ§© Browser Extension</h3>
  <p>Chrome extension for seamless Salesforce integration and automated form completion.</p>
</td>
<td align="center" width="25%">
  <h3>ğŸ› ï¸ Built-in Tools + Notes Intelligence</h3>
  <p>Understands what day it is, can search your notes & customer data wherever they are â€” no more copy/paste.</p>
</td>
<td align="center" width="25%">
  <h3>ğŸ’¬ Chat History & Threads</h3>
  <p>Complete conversation history with thread organization.</p>
</td>
</tr>
<tr>
<td align="center" width="25%">
  <h3>ğŸ”Œ OpenAI Compatible</h3>
  <p>Drop-in API compatibility with existing OpenAI workflows, clients, and integrations.</p>
</td>
<td align="center" width="25%">
  <h3>ğŸ¯ Multiple Backends</h3>
  <p>Works with Ollama or LM Studio â€” use any local LLM you prefer.</p>
</td>
<td align="center" width="25%">
  <h3>ğŸ—ï¸ HashiCorp Expert Mode</h3>
  <p>Deep knowledge of Terraform, Vault, Consul, Nomad â€” including product docs, guides, and best-practice architecture examples.</p>
</td>
<td align="center" width="25%">
  <h3>âœ¨ Smart Suggestions</h3>
  <p>AI-powered contextual suggestions and auto-completion for faster workflows.</p>
</td>
</tr>
</table>

## Development Roadmap

See `roadmap/TODO.md` for planned improvements and upcoming features.

## Chrome Extension

Ivan includes a Chrome extension for automating SE Weekly Updates and WARMER with AI assistance, all directly from within your browser.

![Ivan Extension Screenshot](docs/images/extension-screenshot.png)

### Features

- **Quick Actions**: One-click SE Weekly Update completion, One-click WARMER completion
- **Smart Context**: Automatically extracts opportunity title and user initials from the page, searches your customer notes, and retrieves relevant information
- **Chat Interface**: Conversational refinement of updates before committing
- **Auto-Fill**: Inserts completed updates directly into Salesforce fields

### Installation

1. Navigate to `chrome://extensions` in Chrome
2. Enable "Developer mode"
3. Click "Load unpacked" and select the `ivan-extension` directory
4. Configure the extension to point to your Ivan instance (default: `http://localhost:8000`)

### Usage

1. In Vivun, on the Journeys page, click on an opportunity
2. Click the Ivan extension icon
3. Optionally add additional context in the text input field
4. Click "Complete SE Weekly Update" or "Complete WARMER"
5. Review and refine the generated content through chat
6. Click "Commit" to insert the update into the field

## Quick Start

### Installation

#### Using uv (recommended - fastest and simplest)

```bash
# Clone the repository
git clone https://github.com/assareh/ivan.git
cd Ivan

# Run the setup script (installs uv, Python, and dependencies)
./setup.sh
```

**What the setup script does:**
- Installs uv (if not already installed)
- Installs Python 3.12.0
- Installs all dependencies including Open Web UI
- Creates `.env` from `.env.example` (if not present)
- Applies HashiCorp branding

#### Manual installation with uv

```bash
# Install uv if needed
curl -LsSf https://astral.sh/uv/install.sh | sh

# Clone and setup
git clone https://github.com/assareh/ivan.git
cd Ivan
uv sync --extra webui
cp .env.example .env  # Edit .env to customize settings
./apply_branding.sh
```

### Running Ivan

**Basic usage (default: LM Studio):**
```bash
uv run python ivan.py
# Uses LM Studio backend by default with model: openai/gpt-oss-20b
```

**With Ollama:**
```bash
uv run python ivan.py --backend ollama --model openai/gpt-oss-20b
# Or set via environment variable: export IVAN_BACKEND=ollama
```

**With LM Studio (custom model):**
```bash
uv run python ivan.py --backend lmstudio --model your-model-name
```

**Without Web UI:**
```bash
uv run python ivan.py --no-webui
```

**Custom port:**
```bash
uv run python ivan.py --port 8080
```

**Force rebuild documentation index:**
```bash
uv run python ivan.py --rebuild-index
```


### First Run: Automatic Index Building

**On first use**, Ivan will automatically build a searchable index of HashiCorp documentation. This is a one-time setup process that:

- **Crawls documentation pages** from developer.hashicorp.com
- **Chunks content** using semantic HTML chunking with parent-child relationships
- **Builds a hybrid search index** using FAISS vectors + BM25 keywords
- **Caches the index** in `hashicorp_docs_index/` for instant subsequent searches

The index build process:
- Runs **automatically when Ivan starts** if needed (first run or after 7 days)
- Takes approximately **15-30 minutes** on first build
- Shows **detailed progress** in the terminal with real-time statistics
- Is **cached for 7 days** - after that, Ivan rebuilds automatically on next startup
- Supports **incremental updates** - only new/changed pages are re-indexed

**Manual rebuild:**
- `python ivan.py --rebuild-index` - Force rebuild of the index

**Note**: You can use all other Ivan features (customer notes, general chat, etc.) immediately - only HashiCorp documentation search requires the index.

### Configuration

Ivan can be configured in three ways (listed from highest to lowest priority):

#### 1. Command Line Options (Highest Priority)

Override settings for a single session:

```bash
# Use Ollama with a specific model
python ivan.py --backend ollama --model openai/gpt-oss-20b

# Use LM Studio with custom port
python ivan.py --backend lmstudio --model openai/gpt-oss-20b --port 8080

# Combine multiple options
python ivan.py --backend ollama --model openai/gpt-oss-20b --no-webui --debug
```

#### 2. Environment Variables (Medium Priority)

Set persistent configuration via `.env` file or shell environment:

```bash
# Backend configuration
export IVAN_BACKEND=ollama          # or lmstudio
export BACKEND_MODEL=openai/gpt-oss-20b       # your model name
export OLLAMA_ENDPOINT=http://localhost:11434
export LMSTUDIO_ENDPOINT=http://localhost:1234/v1

# Ivan settings
export IVAN_PORT=8000
export IVAN_TEMPERATURE=0.0
export SYSTEM_PROMPT_PATH=system_prompt.md
export CUSTOMER_NOTES_DIR=Customer_Notes  # Path to customer meeting notes
```

**Using a .env file:**
1. Create `.env` in the Ivan directory (use `.env.example` as a template)
2. Add your settings: `IVAN_BACKEND=ollama`
3. Settings are automatically loaded when Ivan starts

#### 3. Configuration Defaults

All configuration is handled through environment variables (`.env` file). The `config.py` file extends the base configuration but should not be edited directly.

**Note:** The setup script automatically creates `.env` from `.env.example` on first run. This file is not tracked in version control, so you can modify defaults without git conflicts.

#### Context Length Settings

**Important: Set your context length to the maximum supported by your model** for best results. Ivan uses tools and can have long conversations with substantial context, so a larger context window ensures better performance.

**Recommended settings:**
- **For gpt-oss-20b**: Set context length to **131072** (128K tokens)
- **For other models**: Set to the maximum supported by your specific model

**How to configure:**
- **LM Studio**: In the model settings, find "Context Length" or "Max Context" and set it to your model's maximum (e.g., 131072)
- **Ollama**: Configure in your Modelfile with the `num_ctx` parameter:
  ```
  PARAMETER num_ctx 131072
  ```

**Why it matters:**
- Enables longer conversations without losing context
- Supports complex tool calling sequences
- Allows Ivan to reference more of your customer notes and documentation
- Prevents context window truncation during extended sessions

#### Temperature Settings

**Recommended: Set temperature to 0.0 in your LLM backend (Ollama or LM Studio)** for the most deterministic, fact-based responses. This is especially important for:
- Technical documentation queries
- SE Weekly Updates (consistency and accuracy)
- WARMER assessments (precise documentation)
- Customer follow-ups (factual communication)

**Note**: You can experiment with slightly higher temperatures (e.g., 0.1-0.3) if you want more creative or varied responses, but start with 0.0 for best results with structured workflows.

**How to configure:**
- **Ollama**: Set temperature in your Modelfile or via API parameters
- **LM Studio**: Configure temperature in the model settings UI (recommended) or via API
- **Ivan's IVAN_TEMPERATURE**: This sets the default for API requests, but backend settings take precedence

#### Reasoning Level Settings

Some models support different reasoning levels that affect how deeply the model thinks through problems before responding. **For gpt-oss-20b**, you can choose between:

- **Low** - Faster responses with basic reasoning
- **Medium** - Balanced reasoning and speed (recommended starting point)
- **High** - Deeper reasoning for complex problems (slower but more thorough)

**How to configure:**
- **LM Studio**: In the model settings, look for "Reasoning Level" or similar parameter
- **Ollama**: Configure in your Modelfile with model-specific parameters (consult model documentation)

**When to experiment with reasoning levels:**
- **Low**: Quick queries, simple lookups, straightforward documentation searches
- **Medium**: Most SE workflows, meeting summaries, standard technical questions
- **High**: Complex architectural decisions, multi-step problem solving, detailed analysis

**Note**: Not all models support reasoning levels. Check your specific model's documentation for availability and configuration options.

## HashiCorp Branding

Ivan includes HashiCorp branding for the Open Web UI interface. This is applied automatically during the initial setup (`./setup.sh`).

**What gets branded:**
- **HashiCorp logos and favicons** throughout the UI
- **"Ivan" name** replaces all "Open WebUI" text
- **Splash screen** with HashiCorp logo during page loads

The branding assets are stored in the `branding/` directory and can be customized as needed.

**Note**: If you manually upgrade Open Web UI, you can reapply branding with:
```bash
./apply_branding.sh
```

## Usage

### With Open Web UI

1. Start Ivan: `uv run python ivan.py`
2. Open Web UI will automatically start on port 8001 (or port + 1)
3. Access the Web UI at `http://localhost:8001`

The Web UI is pre-configured to use Ivan at `http://localhost:8000/v1` - no login or additional configuration needed!

### With API Clients

Ivan provides an OpenAI-compatible API:

```python
import openai

client = openai.OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="not-needed"
)

response = client.chat.completions.create(
    model="wwtfo/ivan",
    messages=[
        {"role": "user", "content": "What's the current date?"}
    ]
)

print(response.choices[0].message.content)
```

### With curl

```bash
curl http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "wwtfo/ivan",
    "messages": [{"role": "user", "content": "What day is it?"}],
    "temperature": 0
  }'
```

## Tools

Ivan comes with built-in tools that are automatically invoked based on your questions:

| Tool | Trigger | Example Prompts |
|------|---------|-----------------|
| **HashiCorp Doc Search** | Any HashiCorp product question | "How do I configure Vault auto-unseal?", "What's the difference between Consul and Nomad?" |
| **Web Search** | Explicit request or recent news | "Search the web for...", "What's the latest on Terraform 2.0?", "Check current pricing for HCP Vault" |
| **Customer Notes** | Customer name mention | "Show me recent Adobe meetings", "What did we discuss with Acme Corp?" |
| **Current Date/Time** | Date/time questions | "What's today's date?", "What day is it?" |
| **Calculator** | Math operations | "Calculate 15% of 250,000", "Convert 128GB to MB" |

### Tool Priority

For HashiCorp product questions, Ivan uses tools in this order:
1. **hashicorp_doc_search** (always first) - Searches indexed HashiCorp documentation
2. **web_search** (fallback) - Used if docs don't have the answer, or for recent news/announcements

### Triggering Web Search

Ivan automatically uses web search when:
- You explicitly ask: "search the web for...", "look up online...", "check current..."
- You ask about recent news: "latest", "just announced", "what happened this week"
- Doc search doesn't have the answer (automatic fallback)
- Questions about third-party integrations or competitive analysis

### "Check Your Work" Command

For critical questions where you want extra confidence, add "check your work", "verify", or "double check" to your prompt:

```
What's the command to rotate a transit key? Check your work.
```

This triggers Ivan to:
1. Search for the answer
2. Perform a **second search** with a different query to verify
3. Compare results for consistency
4. Respond with higher confidence and multiple source references

### HashiCorp Doc Search

Ivan includes a comprehensive index of HashiCorp documentation including:
- Product docs (Terraform, Vault, Consul, Nomad, Packer, Boundary, Waypoint, Vagrant)
- Validated Design Guides
- Operating Guides (Adoption, Scaling, Standardization)
- Solution Design Guides
- Tutorials and best practices

### Customer Notes Search Tool
Search through customer meeting notes organized in a hierarchical directory structure.

**Setup**: Create a symbolic link to your customer notes:
```bash
ln -s /path/to/your/Customer_Notes ./Customer_Notes
```

Or set the `CUSTOMER_NOTES_DIR` environment variable to point to your notes location.

**Expected Structure**:
```
Customer_Notes/
â”œâ”€â”€ 0-9/
â”œâ”€â”€ A/
â”‚   â””â”€â”€ Adobe/
â”‚       â””â”€â”€ 10_Meetings/
â”‚           â””â”€â”€ 2025-01-15_Discovery_Call.md
â”œâ”€â”€ B/
â””â”€â”€ ...
```

**Smart Name Matching**:
- Automatically converts spaces to underscores
- Case-insensitive substring matching

**Example**: "Show me recent Adobe meetings"

### 3. Read Customer Note Tool
Read the full content of a specific customer meeting note.

**Example**: Used automatically after searching to get full meeting details

## Customization

### System Prompt

Edit `system_prompt.md` to customize Ivan's behavior. The file is automatically cached and reloaded when modified.

### Adding Tools

Add new tools in `tools.py` using the `@tool` decorator:

```python
from langchain_core.tools import tool

@tool
def my_tool(param: str) -> str:
    """Description of what the tool does.

    Args:
        param: Parameter description

    Returns:
        Result string
    """
    return f"Result: {param}"

# Add to ALL_TOOLS list at end of tools.py
ALL_TOOLS = [
    search_customer_notes,
    read_customer_note,
    web_search,
    my_tool,  # Add here
]
```

## API Endpoints

- `GET /health` - Health check
- `GET /v1/models` - List available models
- `POST /v1/chat/completions` - Chat completion endpoint

## CLI Options

```bash
python ivan.py --help

Options:
  --port INTEGER                 Port to run Ivan on (default: 8000)
  --backend [ollama|lmstudio]   Backend to use (default: ollama)
  --model TEXT                   Model name to use with backend
  --no-webui                     Don't start Open Web UI
  --debug                        Run in debug mode
  --help                         Show this message and exit
```

## Requirements

- **Python 3.8+** for Ivan core functionality
- **Python 3.11-3.12** for Open Web UI integration (optional)
  - If you have Python 3.14+, use `--no-webui` flag or set up a separate Python 3.11/3.12 environment
- Ollama or LM Studio running locally
- A compatible model loaded in your backend

### Python Version Setup

Ivan uses **uv** for package management, which automatically handles Python versions.

**Standard setup (recommended):**
```bash
# The setup script handles everything including Python 3.12
./setup.sh

# Or manually with uv:
uv sync --extra webui
```

**If using Python 3.14+ (without Web UI):**
```bash
uv sync  # Install without webui extra
uv run python ivan.py --no-webui
```

## Architecture

```
Ivan
â”œâ”€â”€ ivan.py                  # Main application (uses llm-api-server)
â”œâ”€â”€ config.py                # Configuration (extends ServerConfig)
â”œâ”€â”€ tools.py                 # Tool definitions (LangChain)
â”œâ”€â”€ system_prompt.md         # System prompt (customizable)
â”œâ”€â”€ pyproject.toml           # Python dependencies and project config
â”œâ”€â”€ Customer_Notes/          # Symlink to customer meeting notes (optional)
â”œâ”€â”€ hashicorp_docs_index/    # Cached documentation index (auto-generated)
â””â”€â”€ ivan-extension/          # Chrome extension for Salesforce
```

Ivan is built on [llm-api-server](https://github.com/assareh/llm-api-server), a reusable Flask server for LLM backends with tool calling. This provides:
- OpenAI-compatible API endpoints
- Ollama and LM Studio backend support
- Tool execution with streaming responses
- Optional Open Web UI integration
- RAG (Retrieval-Augmented Generation) for documentation search

## Certification Test Suite

Ivan includes a regression test suite for HashiCorp certification exam questions to validate RAG accuracy and LLM reasoning capabilities.

### Running Tests

```bash
# Basic run (requires Ivan to be running)
python tests/test_certification.py

# Generate HTML report
python tests/test_certification.py --html tests/certification_report.html

# Generate JSON report
python tests/test_certification.py --json tests/certification_results.json

# Verbose output with response previews
python tests/test_certification.py -v

# Run limited number of tests
python tests/test_certification.py -n 10
```

### Test Coverage

| Certification | Questions | Types |
|--------------|-----------|-------|
| Vault Associate (003) | 16 | True/False, Multiple Choice, Multiple Answer |
| Consul Associate (003) | 7 | True/False, Multiple Choice, Multiple Answer |
| Terraform Associate (003) | 16 | True/False, Multiple Choice, Multiple Answer |
| **Total** | **39** | |

### Results by Model

Results vary based on the LLM backend used. Below are benchmark results from testing:

| Model | Pass Rate | Avg Response Time | Notes |
|-------|-----------|-------------------|-------|
| *Coming soon* | - | - | Results will be added as models are tested |

> **Note**: Test results depend on RAG index quality, model capabilities, and configuration settings. Your results may vary.

## Troubleshooting

**Ivan can't connect to Ollama/LM Studio:**
- Ensure your backend is running
- Check the endpoint configuration matches your backend
- Verify the model name is correct

**Tools not working:**
- Ensure your system prompt allows tool usage
- Verify the backend model supports function calling
- For customer notes: check that the Customer_Notes symlink or directory exists

**Open Web UI not starting:**
- Install it manually: `pip install open-webui`
- Or run with `--no-webui` and start it separately

## License

MIT

